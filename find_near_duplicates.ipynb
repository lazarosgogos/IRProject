{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to find near duplicates using the SimHash technique, and organizing them in an M-Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import similarities.mtree\n",
    "import importcsv\n",
    "import similarities.libsim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing csv file...........\n"
     ]
    }
   ],
   "source": [
    "print('Importing csv file...........')\n",
    "small_dataset = importcsv.opencsv('processedspeech.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κρατάω μόνο τα processed speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = small_dataset['processed_speeches']\n",
    "# speeches = small_dataset['speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         ΠΑΡΑΚΑΛΕΙΤΑ ΚΥΡΙ ΓΡΑΜΜΑΤΕ ΣΥΝΟΔΕΥΣ ΙΕΡ ΣΥΝΟΔ Α...\n",
      "1         ΥΠΑΡΧ ΕΚ ΚΥΡΙ ΣΥΝΑΔΕΛΦ ΨΗΦΙΣ ΚΗΡΥΣΣΕΤΑ ΠΕΡΑΙΩΜ...\n",
      "2         ΚΥΡΙ ΒΟΥΛΕΥΤ ΤΙΜ ΑΝΑΚΟΙΝΩΣ ΣΩΜ ΒΟΥΛΕΥΤ ΕΒΡ ΥΠΟ...\n",
      "3         ΥΠΑΡΧ ΕΚ ΚΥΡΙ ΣΥΝΑΔΕΛΦ ΕΨΗΦΙΣ ΚΗΡΥΣΣΕΤΑ ΠΕΡΑΙΩ...\n",
      "4         ΚΥΡΙ ΣΥΝΑΔΕΛΦ ΤΙΜ ΑΝΑΚΟΙΝΩΣ ΑΠΟΤΕΛΕΣΜ ΔΙΕΞΑΧΘΕ...\n",
      "                                ...                        \n",
      "362625    Π ΤΕΘ ΠΕΡΙΟΡΙΣΜ ΠΑΜ ευρωπαϊκη ΕΝΩΣ ΖΗΤΑΜ ΛΕΜ ...\n",
      "362626    ΥΠΗΡΧΕΕΜ ΑΝΑΠΤΥΞΙΑΚ ΥΠΟΥΡΓΕΙ ΥΠΟΥΡΓΕΙ ΚΑΝ ΚΟΙΝ...\n",
      "362627    ΕΥΧΑΡΙΣΤΟΥΜ ΥΠΟΥΡΓ ΚΗΡΥΣΣΕΤΑ ΠΕΡΑΙΩΜΕΝ ΣΥΖΗΤΗΣ...\n",
      "362628    ΟΛΟΚΛΗΡΩΣ ΨΗΦΟΦΟΡΙ ΗΛΕΚΤΡΟΝΙΚ ΣΥΣΤΗΜ ΣΧΕΔΙ ΝΟΜ...\n",
      "362629    ΣΥΝΑΙΝΕΣ ΣΩΜΑΤ ΩΡ 1949΄ ΛΥΕΤΑ ΣΥΝΕΔΡΙΑΣ ΔΕΥΤΕΡ...\n",
      "Name: processed_speeches, Length: 362630, dtype: object\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(speeches)\n",
    "print(type(speeches[0]))\n",
    "# speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the weights of each word for all speeches, and keep them in a dictionary.\n",
    "The dictionary is of the form {word: weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shall come in handy\n",
    "# https://www.reddit.com/r/LanguageTechnology/comments/dugjis/approximate_string_matching_with_simhash_and_a/\n",
    "\n",
    "# del vectorizer, X\n",
    "# speeches = speeches.to_list()\n",
    "vectorizer = TfidfVectorizer(encoding='utf-8', lowercase=False)\n",
    "X = vectorizer.fit_transform(speeches.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '0000' '000000' '000000395' '00003' '0001' '00010' '000100'\n",
      " '000102' '00010ο' '00011' '000112' '00012' '000123' '00013' '000133'\n",
      " '00014' '000144' '000145' '00015' '000155' '00016' '000167' '00017'\n",
      " '000178' '00018' '000189' '00019' '0001911' '000192' '0001Α' '0002'\n",
      " '00020' '0002013' '00021' '0002116' '00022' '00023' '00024' '00025'\n",
      " '000255' '00026' '00027' '00028' '000297' '0002Θεωρούμε' '0002γράφημά'\n",
      " '0003' '000319' '0003επιλέξει' '0004' '0004γών' '0005' '0006' '000603'\n",
      " '000635' '00067' '0006Α' '0006Β' '0006που' '0007' '000716' '0008' '00081'\n",
      " '000858' '0008μοκρατία' '0008ο' '0009' '00091' '000927' '0009Α'\n",
      " '0009ορισμένες' '000MW' '000V' '000cc' '000l' '000m3' '000Έτος' '000Αυτά'\n",
      " '000Για' '000Διδακτικό' '000Ε' '000Η' '000Ο' '000ΣΕΛΙΔΑ' '000Σύνολο'\n",
      " '000Τα' '000Υπερβάλλον' '000Ως' '000άλλοτε' '000β' '000γ' '000δ'\n",
      " '000δραχμές' '000δραχμών' '000δρχ' '000ε' '000επί' '000ευρώ' '000ζ'\n",
      " '000η' '000και' '000καταστηματάρχες' '000μονάδων' '000νται' '000πάνω'\n",
      " '000προηγούμενηςμετ' '000στ' '000στρ' '000στρέμματα' '000στρεμμάτων'\n",
      " '000τ' '000τα' '000υπερβάλλον' '000χιλ' '001' '0010' '00102' '0010λογή'\n",
      " '0010μερη' '0010νόμους' '0011' '00118' '0011995' '0011δύο' '0012'\n",
      " '0012αναφερθώ' '0012βήτηση' '0013']\n"
     ]
    }
   ],
   "source": [
    "names = vectorizer.get_feature_names_out()\n",
    "index = 000\n",
    "\n",
    "print(names[index:index+130])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
