{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing csv file...........\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "sys.path.append('../keywords/')\n",
    "\n",
    "import importcsv\n",
    "\n",
    "print('Importing csv file...........')\n",
    "small_dataset = importcsv.opencsv('../processedspeechfinal.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_name_list = small_dataset['member_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "from word_frequency_calculator import filter_dataframe\n",
    "from k_decomposition import getkeywords\n",
    "\n",
    "member_vector = {}\n",
    "counter = 0\n",
    "for name in member_name_list:\n",
    "    counter +=1\n",
    "    if counter%100 == 0:\n",
    "        print(counter)\n",
    "    member_speeches = filter_dataframe(small_dataset, member=name).to_list()\n",
    "    keywords = getkeywords(member_speeches)\n",
    "    member_vector[name] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the inverted catalog to a json file\n",
    "import json\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"member_ch_vectorfinal.json\"\n",
    "\n",
    "# Save the dictionary to a file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(member_vector, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the unique member names\n",
    "names = small_dataset['member_name'].unique()\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a string of the keywords list (else prob with TfidVectorizer)\n",
    "words1 = []\n",
    "for words in member_vector.values():\n",
    "    words1.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidvectorizer as usual\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tfidvectorizer = TfidfVectorizer(lowercase=False)\n",
    "matrix = tfidvectorizer.fit_transform(words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "# Cosine similarity for a member against all the other members and return top k \n",
    "def find_similar(member_name, matrix, k=10):\n",
    "    similarity_per_member = {}\n",
    "    \n",
    "    ddsim_matrix = cosine_similarity(matrix[member_name,:],matrix)\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        if ddsim_matrix[0,i] > 0:\n",
    "            similarity_per_member[i] = ddsim_matrix[0,i] \n",
    "    \n",
    "    top_k_items = nlargest(k+1, similarity_per_member.items(), key=lambda x: x[1])\n",
    "\n",
    "    return [member[0] for member in top_k_items[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict with keys the members and values a list of the top k similar members \n",
    "pairs_similarity = {}\n",
    "\n",
    "for i, member in enumerate(names):\n",
    "    similar = find_similar(i,matrix)\n",
    "    pairs_similarity[member] = [names[i] for i in similar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the inverted catalog to a json file\n",
    "import json\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"member_similaritiesfinal.json\"\n",
    "\n",
    "# Save the dictionary to a file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(pairs_similarity, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
